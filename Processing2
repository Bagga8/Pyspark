#installing pyspark
!pip install pyspark

#importing pyspark
from pyspark.sql import pyspark

#import a spark session
from pyspark.sql import Sparksession

#create a spark session
spark = SparkSession.builder.master("local[*]").getOrCreate

#importing files
from google.colab import files 
files.upload()

#creating data frame and load it
df = spark.read.format("csv").option("header", "true").option("mode", "failfast").load("PySpark_data.csv")

#get output
df.show(3)

#Creating a temporary view
df.createOrReplaceTempView("PySpark_data")

#processing in spark.sql
spark.sql("select * from PySpark_data")

#Storing data in a variable
x = select("select avg(age) from PySpark_data").collect()[0][0]

#using the stored vaiable
print(x +2)

#processing in spark.sql
spark.sql("select avg(age) as A, country from PySpark_data order by country").show

#processing in spark.sql
spark.sql("select * from PySpark_data where age>=25 AND <=30).show()

#refering to dataframe with spark.sql
df.groupby("country").avg("age").orderBy("id", ascending = False).show()

