#installing pyspark
!pip install pyspark

#importing pyspark
from pyspark.sql import pyspark

#import a spark session
from pyspark.sql import Sparksession

#create a spark session
spark = SparkSession.builder.master("local[*]").getOrCreate

#importing files
from google.colab import files 
files.upload()

#creating data frame and load it
df = spark.read.format("csv").option("header", "true").option("mode", "failfast").load("PySpark_data.csv")

#get output
df.show(3)

#Creating a temporary view
df.createOrReplaceTempView("PySpark_data")

#processing in spark.sql
spark.sql("select * from PySpark_data")

#Processsing in spark.sql
spark.sql(select count(*) from PySpark_data group by age").show

#Processsing in spark.sql
spark.sql(select name from PySpark_data where age < 30").show

